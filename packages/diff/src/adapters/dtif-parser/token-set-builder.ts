import type { ParseDocumentResult } from '@lapidist/dtif-parser';
import {
  JSON_POINTER_ROOT,
  createDocumentResolver,
  InMemoryDocumentCache,
  normalizeJsonPointer,
  parseDocument,
  parseTokensSync,
} from '@lapidist/dtif-parser';
import type { Diagnostic, JsonPointer } from '@lapidist/dtif-parser';
import { createDtifValidator } from '@lapidist/dtif-validator';

import type { TokenSet } from '../../domain/tokens.js';
import {
  append,
  createTokenSetFromParseResult as createTokenSetFromParseResultCore,
  resolveSourceUri,
  type ParserHooks,
} from '@dtifx/core';
import type { DesignTokenInterchangeFormat } from '@lapidist/dtif-schema';

export type RawTokenTree = DesignTokenInterchangeFormat;

type TokenParserHooks = ParserHooks<Diagnostic>;

interface CreateTokenSetOptions extends TokenParserHooks {
  readonly source?: string;
  readonly prefix?: readonly string[];
}

const FILE_DOCUMENT_CACHE = new InMemoryDocumentCache({ maxEntries: 32 });
const INLINE_SCHEMA_VALIDATOR = createDtifValidator();
const SCHEMA_VALIDATION_ERROR_CODE = 'SCHEMA_VALIDATION_ERROR';

export type { TokenParserHooks };

/**
 * Parses a DTIF token document using the shared document cache and provided parser hooks.
 *
 * @param filePath - The filesystem path of the DTIF document.
 * @returns The parser result containing the decoded document and graph.
 */
export async function parseTokenDocument(filePath: string): Promise<ParseDocumentResult> {
  if (typeof filePath !== 'string') {
    throw new TypeError('parseTokenDocument expects a file path string.');
  }

  return parseDocument(filePath, { documentCache: FILE_DOCUMENT_CACHE });
}

/**
 * Forwards diagnostics emitted during parsing to the configured hooks.
 *
 * @param diagnostics - The diagnostics generated by the parser.
 * @param hooks - Hook callbacks that receive diagnostics and warnings.
 */
export function forwardDiagnostics(
  diagnostics: Iterable<Diagnostic>,
  hooks: TokenParserHooks,
): void {
  for (const diagnostic of diagnostics) {
    hooks.onDiagnostic?.(diagnostic);

    if (diagnostic.severity === 'warning') {
      hooks.warn?.(diagnostic);
    }
  }
}

/**
 * Throws an error when the diagnostics collection contains fatal parser errors.
 *
 * @param diagnostics - Diagnostics emitted by the parser.
 * @param source - Description of the source being parsed for error reporting.
 */
export function ensureNoFatalDiagnostics(diagnostics: Iterable<Diagnostic>, source: string): void {
  if (hasSeverity(diagnostics, 'error')) {
    throw new Error(formatDiagnostics(source, diagnostics));
  }
}

/**
 * Formats parser diagnostics into a human-readable string for error messages.
 *
 * @param source - Description of the source being parsed.
 * @param diagnostics - Diagnostics to format.
 * @returns The formatted diagnostic summary.
 */
export function formatDiagnostics(source: string, diagnostics: Iterable<Diagnostic>): string {
  const messages: string[] = [];

  for (const diagnostic of diagnostics) {
    const parts: string[] = [];

    if (diagnostic.pointer) {
      append(parts, diagnostic.pointer);
    }

    if (diagnostic.span) {
      append(
        parts,
        `line ${String(diagnostic.span.start.line)}, column ${String(diagnostic.span.start.column)}`,
      );
    }

    const location = parts.length > 0 ? ` (${parts.join(' ')})` : '';
    const code = diagnostic.code;

    messages.push(`${diagnostic.severity.toUpperCase()} ${code}: ${diagnostic.message}${location}`);
  }

  if (messages.length === 0) {
    return `Failed to parse DTIF document: ${source}`;
  }

  return `Failed to parse DTIF document ${source}:\n${messages.join('\n')}`;
}

/**
 * Creates a token set from a raw DTIF tree without a parser graph.
 *
 * @param tree - The raw DTIF token tree.
 * @param options - Additional options controlling prefixing and source metadata.
 * @returns The constructed token set.
 */
export function createTokenSetFromTree(
  tree: RawTokenTree,
  options: CreateTokenSetOptions = {},
): TokenSet {
  if (!isRecord(tree)) {
    throw new Error('Token tree must be an object');
  }

  const sourceUri = resolveSourceUri(options.source);
  const prefix = options.prefix ?? [];
  const wrapped = wrapTreeWithPrefix(tree, prefix);

  validateInlineTree(wrapped, options, sourceUri.href);

  const parseTokensResult = parseTokensSync(
    {
      uri: sourceUri.href,
      data: wrapped,
      contentType: 'application/json',
    },
    {
      includeGraphs: true,
      flatten: true,
    },
  );

  forwardDiagnostics(parseTokensResult.diagnostics, options);
  ensureNoFatalDiagnostics(parseTokensResult.diagnostics, options.source ?? sourceUri.href);

  const identity =
    parseTokensResult.document?.identity ?? createInlineIdentity(sourceUri, 'application/json');

  const parseResult: ParseDocumentResult = {
    ...(parseTokensResult.document === undefined ? {} : { document: parseTokensResult.document }),
    ...(parseTokensResult.graph === undefined
      ? {}
      : { graph: { identity, graph: parseTokensResult.graph } }),
    ...(parseTokensResult.resolver === undefined
      ? {}
      : { resolution: { identity, result: parseTokensResult.resolver, diagnostics: [] } }),
    diagnostics: parseTokensResult.diagnostics,
    fromCache: false,
  } satisfies ParseDocumentResult;

  return createTokenSetFromParseResult(parseResult, {
    ...(options.source === undefined ? {} : { source: options.source }),
    ...(options.onDiagnostic === undefined ? {} : { onDiagnostic: options.onDiagnostic }),
  });
}

interface AjvErrorLike {
  readonly instancePath?: string;
  readonly message?: string;
  readonly keyword?: string;
}

function validateInlineTree(
  tree: RawTokenTree,
  hooks: TokenParserHooks,
  sourceLabel: string,
): void {
  const valid = INLINE_SCHEMA_VALIDATOR.validate(tree);

  if (valid) {
    return;
  }

  const rawErrors = Array.isArray(INLINE_SCHEMA_VALIDATOR.validate.errors)
    ? (INLINE_SCHEMA_VALIDATOR.validate.errors as readonly AjvErrorLike[])
    : [];

  const diagnostics: Diagnostic[] =
    rawErrors.length > 0
      ? rawErrors.map((error) => convertAjvErrorToDiagnostic(error))
      : [
          {
            code: SCHEMA_VALIDATION_ERROR_CODE,
            message: 'Inline DTIF payload failed schema validation.',
            severity: 'error',
            pointer: JSON_POINTER_ROOT,
          } satisfies Diagnostic,
        ];

  forwardDiagnostics(diagnostics, hooks);

  throw new Error(formatDiagnostics(sourceLabel, diagnostics));
}

function convertAjvErrorToDiagnostic(error: AjvErrorLike): Diagnostic {
  const pointer = normalizeAjvInstancePath(error.instancePath);
  const keyword =
    typeof error.keyword === 'string' && error.keyword.length > 0
      ? error.keyword.toUpperCase()
      : 'UNKNOWN';
  const message =
    typeof error.message === 'string' && error.message.length > 0
      ? error.message
      : 'Schema validation error';

  return {
    code: `${SCHEMA_VALIDATION_ERROR_CODE}:${keyword}`,
    message,
    severity: 'error',
    pointer,
  } satisfies Diagnostic;
}

function normalizeAjvInstancePath(path: string | undefined): JsonPointer {
  if (typeof path !== 'string' || path.length === 0) {
    return JSON_POINTER_ROOT;
  }

  try {
    return normalizeJsonPointer(path);
  } catch {
    return JSON_POINTER_ROOT;
  }
}

/**
 * Hydrates a token set from a parser result and returns a mutable map of snapshots for diff
 * consumers.
 *
 * @param result The parser result containing the decoded DTIF document and graph.
 * @param options Additional options describing the originating source label.
 * @param options.source Optional label applied to the hydrated token set.
 * @returns The hydrated token set.
 */
export function createTokenSetFromParseResult(
  result: ParseDocumentResult,
  options: { readonly source?: string } & TokenParserHooks,
): TokenSet {
  const tokenSet = createTokenSetFromParseResultCore(result, {
    ...(options.source === undefined ? {} : { source: options.source }),
    ...(options.onDiagnostic === undefined ? {} : { onDiagnostic: options.onDiagnostic }),
    createDocumentResolver,
  });

  return {
    ...tokenSet,
    tokens: new Map(tokenSet.tokens),
  } satisfies TokenSet;
}

function hasSeverity(diagnostics: Iterable<Diagnostic>, severity: Diagnostic['severity']): boolean {
  for (const diagnostic of diagnostics) {
    if (diagnostic.severity === severity) {
      return true;
    }
  }

  return false;
}

function wrapTreeWithPrefix(tree: RawTokenTree, prefix: readonly string[]): RawTokenTree {
  if (prefix.length === 0) {
    return tree;
  }

  let wrapped: RawTokenTree = tree;

  for (let index = prefix.length - 1; index >= 0; index -= 1) {
    wrapped = {
      [prefix[index] ?? '']: wrapped,
    } as RawTokenTree;
  }

  return wrapped;
}

function isRecord(value: unknown): value is Record<string, unknown> {
  return Boolean(value) && typeof value === 'object' && !Array.isArray(value);
}

function createInlineIdentity(
  uri: URL,
  contentType: 'application/json' | 'application/yaml',
): { readonly uri: URL; readonly contentType: 'application/json' | 'application/yaml' } {
  return { uri, contentType };
}
